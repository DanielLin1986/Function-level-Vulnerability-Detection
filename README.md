# Function-level Vulnerability Detection

Hello, this fork of the project develop by [DanielLin](https://github.com/DanielLin1986/Function-level-Vulnerability-Detection) has the purpose of been presented for the Data Security Exam a.y.2023/24.

Before starting, it is a good advice to run everything into a controlled environment, we have used anaconda for creating our virtual env, but also other solutions (like venv) can be suitable for that.

### Set up Virtual Environment

In Anaconda:
```
conda create -n vulerabilityDetection python=3.7 scikit-learn scikit-image pandas matplotlib numpy cuda cudnn -c nvidia
```

Then activate the environment just created:
```
conda activate vulerabilityDetection
```

### Install the requirements

Starting from the root folder of the project, install/upgrade pip for installing Python required packages
```
pip install pip --upgrade
```

Now install the requirements
```
pip install -U -r requirements.txt
```

### Unzip the Data

At this point the source Dataset should be unzipped before start working, to do that, if you're working on Windows system just go into the data folder and unzip the LibPNG.zip
```
cd data
tar -xf LibPNG.zip
```

The results will be a folder with two subfolders: Vulnerable and Non-Vulnerable functions.



### Run the process

At this point everything should be set for launching the main process by passing it the yaml configuration file which will lead the process.
```
Python main.py --config config\config.yaml
```

with the current configuration the tokenizer starts the embedding of the source data by using the tokenizer.pickle module which will create the w2v_model.txt with the embeddings.

These embeddings will feed the the NN chosen into the config.yaml. 

The default one is the LSTM, but it is possible to change it by choosing between different options like:
- GRU
- BiLSTM
- BiGRU
- DNN

The process so will take the embeddings generated by the tokenizer and will perform the training and validation against the chosen model.
The output of the process and its parameters will be available into the **logs** subfolder created during the process.


