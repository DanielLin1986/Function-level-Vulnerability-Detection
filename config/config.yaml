embedding_settings:
    data_path: 'data/'                                # The path of the code base for training the embedding model.
    embedding_model_saved_path: 'embedding/'             # The output path of the trained embedding model.
    seed: 1                                            # Seed for the random number generator.
    n_workers: 4                                       # Number of threads for training.
    word2vec:
        size: 100                                      # Dimensionality of the word vectors. This is the Embedding dimension.
        window: 5                                       # Maximum distance between the current and predicted word within a sentence.
        min_count: 5                                    # Ignores all words with total frequency lower than this.
        algorithm: 0                                    # Training algorithm: 1 for skip-gram; otherwise CBOW.
    glove:
        components: 100                                # Dimensionality of the output word vectors. This is the Embedding dimension.
        window: 5                                      # Maximum distance between the current and predicted word within a sentence.
        epoch: 40                                      # Number of iterations (epochs) over the corpus.
        learning_rate: 0.001                           # Learning rate for training
    fasttext:
        size: 100
        window: 5                                       # Maximum distance between the current and predicted word within a sentence.
        min_count: 5                                    # Ignores all words with total frequency lower than this.
        algorithm: 0                                    # Training algorithm: 1 for skip-gram; otherwise CBOW.
        epoch: 20                                       # Number of iterations (epochs) over the corpus.


model_settings:
  model: 'elmo'                             # Choose the model to be trained (currently, the code supports the DNN, RNNs (i.e., LSTM and GRU ), BiRNN (i.e., bidirectional LSTM and bidirectional GRU), and textCNN)
  optimizer: 
    type: 'sgd'                                # Optimizer used for training (SGD)
  loss_function: 'binary_crossentropy'         # The loss function used

  model_para:
    handle_data_imbalance: True
    max_sequence_length: 1000
    use_dropout: True
    dropout_rate: 0.5
    dnn_size: 128                             # The number of neurons used for DNN (the first layer)
    rnn_size: 128                             # The number of neurons used for RNN (the first layer)
    birnn_size: 64                            # The number of neurons used for Bi-RNN (the first layer)
    embedding_trainable: False
    

training_settings:
    dataset_config:
        Test_set_ratio: 0.2                   # If not using a separate test set, set the test set ratio.  
        Validation_set_ratio: 0.2             # Use part of the training set as the validation set. 

    network_config:
        batch_size: 16
        epochs: 150
        patcience: 35
        save_training_history: True
        plot_training_history: True
        validation_metric: 'val_loss'
        
    save_best_model: True
    using_separate_test_set: False           # If this is set to True, please specify the path of test set.
    test_set_path: 'test/'                   # If users do not use the a separate test set, this setting is ignored.
    period_of_saving: 1
    log_path: 'logs/'
    model_save_path: 'result/models/'
    model_saved_name: 'test_model'
